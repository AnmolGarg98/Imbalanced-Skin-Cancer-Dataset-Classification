{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/home/nidhi2023/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(False) # Needed for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c isic-2024-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>sex</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>image_type</th>\n",
       "      <th>tbp_tile_type</th>\n",
       "      <th>tbp_lv_A</th>\n",
       "      <th>...</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>iddx_full</th>\n",
       "      <th>iddx_1</th>\n",
       "      <th>iddx_2</th>\n",
       "      <th>iddx_3</th>\n",
       "      <th>iddx_4</th>\n",
       "      <th>iddx_5</th>\n",
       "      <th>mel_mitotic_index</th>\n",
       "      <th>mel_thick_mm</th>\n",
       "      <th>tbp_lv_dnn_lesion_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015670</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_1235828</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>3.04</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>20.244422</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.517282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015845</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_8170065</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>1.10</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>31.712570</td>\n",
       "      <td>...</td>\n",
       "      <td>IL_6727506</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.141455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015864</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_6724798</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>3.40</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>22.575830</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.804040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0015902</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_4111386</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>3.22</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>14.242329</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.989998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0024200</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_8313778</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>2.73</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>24.725520</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.442510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id  target  patient_id  age_approx   sex anatom_site_general  \\\n",
       "0  ISIC_0015670       0  IP_1235828        60.0  male     lower extremity   \n",
       "1  ISIC_0015845       0  IP_8170065        60.0  male           head/neck   \n",
       "2  ISIC_0015864       0  IP_6724798        60.0  male     posterior torso   \n",
       "3  ISIC_0015902       0  IP_4111386        65.0  male      anterior torso   \n",
       "4  ISIC_0024200       0  IP_8313778        55.0  male      anterior torso   \n",
       "\n",
       "   clin_size_long_diam_mm          image_type tbp_tile_type   tbp_lv_A  ...  \\\n",
       "0                    3.04  TBP tile: close-up     3D: white  20.244422  ...   \n",
       "1                    1.10  TBP tile: close-up     3D: white  31.712570  ...   \n",
       "2                    3.40  TBP tile: close-up        3D: XP  22.575830  ...   \n",
       "3                    3.22  TBP tile: close-up        3D: XP  14.242329  ...   \n",
       "4                    2.73  TBP tile: close-up     3D: white  24.725520  ...   \n",
       "\n",
       "    lesion_id  iddx_full  iddx_1  iddx_2  iddx_3  iddx_4  iddx_5  \\\n",
       "0         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
       "1  IL_6727506     Benign  Benign     NaN     NaN     NaN     NaN   \n",
       "2         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
       "3         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
       "4         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   mel_mitotic_index  mel_thick_mm  tbp_lv_dnn_lesion_confidence  \n",
       "0                NaN           NaN                     97.517282  \n",
       "1                NaN           NaN                      3.141455  \n",
       "2                NaN           NaN                     99.804040  \n",
       "3                NaN           NaN                     99.989998  \n",
       "4                NaN           NaN                     70.442510  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matadata = pd.read_csv(\"../../wgangp/train-metadata.csv\", low_memory=False)\n",
    "train_matadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoader(Dataset):\n",
    "    def __init__(self, df, file_hdf, transform=None):\n",
    "        self.df = df\n",
    "        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n",
    "        # self.isic_ids = df[df['target']!=1]['isic_id'].values\n",
    "        self.isic_ids = df['isic_id'].values\n",
    "#         self.targets = df['target'].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        isic_id = self.isic_ids[index]\n",
    "        # print(isic_id)\n",
    "        image = Image.open(BytesIO(self.fp_hdf[isic_id][()]))\n",
    "#         target = self.targets[index]\n",
    "#         image = torch.permute(image,(2,1,0))\n",
    "        if self.transform:\n",
    "            return (self.transform(image))\n",
    "        else:\n",
    "            return (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                               transforms.Resize(128),\n",
    "                               transforms.CenterCrop(128),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ])\n",
    "\n",
    "train_dataset_full = ImageLoader(train_matadata,\n",
    "                      file_hdf = \"../../wgangp/train-image.hdf5\",\n",
    "                      transform=train_transforms\n",
    "                     )\n",
    "\n",
    "\n",
    "# train_size = int(0.7 * len(train_dataset_full))\n",
    "# test_size = len(train_dataset_full) - train_size\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(train_dataset_full, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401059"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train_dataset_full, batch_size=128,num_workers=8,shuffle=True)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "ds = iter(dataloader)\n",
    "\n",
    "\n",
    "# next(ds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),  # (3, 156, 156) -> (64, 78, 78)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # (64, 78, 78) -> (128, 39, 39)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),  # (128, 39, 39) -> (256, 20, 20)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # (128, 39, 39) -> (256, 20, 20)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # (128, 39, 39) -> (256, 20, 20)\n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten(),  # Image grid to single feature vector\n",
    "            nn.Linear(128 * 16 , latent_dim),\n",
    "        )\n",
    "        self.linear = nn.Sequential(nn.Linear(latent_dim, 128 * 16 ), nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # (256, 20, 20) -> (128, 39, 39)\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # (128, 39, 39) -> (64, 78, 78)\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # (64, 78, 78) -> (3, 156, 156)\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        # print(x.shape)\n",
    "        # y = self.linear(x)\n",
    "        # y = y.reshape(y.shape[0], -1, 4, 4)\n",
    "        # y = self.decoder(y)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = Autoencoder(latent_dim=256).cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_loss = 9999\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = 0\n",
    "    for img in tqdm.tqdm(dataloader):\n",
    "        img = img.cuda()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() / len(dataloader)\n",
    "    output = output.mul(0.5).add(0.5)\n",
    "    img = img.mul(0.5).add(0.5)\n",
    "    vutils.save_image(output,'./samples/samples_{}.jpg'.format(epoch))\n",
    "    vutils.save_image(img,'./samples/input_{}.jpg'.format(epoch))\n",
    "    if avg_loss < max_loss :\n",
    "        torch.save(model.state_dict(), 'min_loss_autoencoder.pth')\n",
    "        max_loss = avg_loss\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'autoencoder.pth')\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
